поток это:
 • Средство параллельного относительно других потоков исполнения кода;
 • Имеющего общий доступ ко всем ресурсам процесса.

По сути поток — это средство эмуляции параллельного исполнения относительно других потоков

У нас состояние ожидания называется блокировкой. Имея ввиду, что блокируется ожидающий поток, но чаще всего не даётся никаких комментариев, что это значит. А значит это то, что поток более не участвует в планировании планировщиком потоков. Т.е. полностью исключается и не влияет на производительность: как будто и нет его.

Поэтому чтобы "переключить" исполнение процессором кода одного потока на другой, необходимо сохранить где-то значения всех регистров для текущего потока, условного "первого", а потом -- восстановить из другого места значения регистров другого потока, ранее таким же образом "поставленного на паузу".

У процессора есть специальные часы: системный таймер
Однако, конечно же, когда операционная система планирует 100500 потоков на 32 ядрах, она их делит между потоками как и в случае одного ядра.

код вашей программы может прерваться в абсолютно любом месте на время от 20 мс до... неизвестно, скольки

CPU-bound код, исполняясь не обращается ни к каким устройствам: ни к сети ни к диску ни к чему-либо ещё. Он либо математический либо обрабатывает какие-то графы или парсит данные. В общем такой код использует только процессор.

I/O bound код, исполняясь, обращается к различным устройствам и потому постоянно находится с точки зрения CPU в блокировке: ожидая некоторое устройство либо сигнал от другого потока. С точки зрения операционной системы это прекрасный шанс дать другому потоку выполнить код: текущему же процессор пока

• пока одни потоки ждут оборудования, другие -- работают. Поэтому в один момент времени работает не так много потоков и программа вполне активно может работать, используя сотню потоков и 8 ядер.
• исполнение кода может быть прервано в абсолютно любой момент. Например посередине исполнение кода: a = b;, когда b уже считано, а вот в a ещё не записали;

также поэтому нет смысла делать много CPU-bound потоков. Код от этого работать быстрее не станет: эти потоки будут делить те же самые ядра

Самый низкий приоритет (#1) имеет Zero Page Thread. Это -- специальный поток операционной системы, который обнуляет страницы оперативной памяти, вычищая тем самым данные, которые там находились, но более не нужны, т.к. страница была освобождена

Мало того, повышение приоритета у некоторого потока относительно других увеличит его время исполнения, да. Но и уменьшит время исполнения остальных потоков. Это приведет к проседанию метрик стандартного пула потоков .NET и как результат (он-то не в курсе что есть высокоприоритетный поток) пул начнёт накидывать потоков для увеличения уровня параллелизма


Для чего это необходимо? Вы как программисты знаете модель многопоточности, которая у вас присутствует. Потоков может быть много и вы решаете, что один поток должен быть фоновым, так как он, например, считает какие-то метрики или вычисления и вам не столь важно, когда данные станут доступны: важно чтобы поток когда-нибудь завершил вычисления (например поток обхода и анализа дерева). Поэтому, вы устанавливаете пониженный приоритет данного потока. Аналогично может сложится ситуация когда необходимо запустить поток с повышенным приоритетом

Каждому потоку даётся накоторый промежуток времени, в течении которого он может исполняться прежде чем его прервут чтобы отдать время другому. Этот промежуток называется квантом

Когда же поток отрабатывает свой квант времени, планировщик его переводит в состояние Ready или Waiting. В состояние Waiting поток входит в том случае, если он входит блокировку (блокировки уровня ядра: mutex, semaphore, работа с дисковой системой ввода/вывода и т.п.)

Когда поток находится в состоянии Waiting, процессор вообще не тратит время на данный поток т.к. он исчезает из планирования. Когда блокировка будет снята (например, event.Set()), поток переводится в состояние Ready и после того, как до него доходит очередь он начинает выполняться

За каждым ядром операционная система закрепляет свой планировщик потоков

Квант, выделяемый одному потоку варьируется от системы к системе и может быть равен 20 мcек в пользовательском режиме ОС Windows. Это значит, что каждый поток получит время на исполнение примерно 1 раз в 50 * 20 = 1000 мсек. Т.е. один раз в секунду на 20 мcек

Второе понятие, которое необходимо рассмотреть - понятие системного таймера. Системный таймер - это аппаратное устройство, суть которого заключается в том чтобы очень точно с одинаковым диапазоном подавать импульс на некоторое специально для этого предназначенное место в процессоре, вызывая тем самым прерывание. Прерывание -- это вызов кода операционной системы путём вызова функции по некоторому индексу в таблице прерываний.

На однопроцессорной системе x86 работа ситемного таймера настроена на срабатывание каждые 10 мсек, тогда как на многопроцессорной системе -- на 15 мсек.

Одну треть диапазона между срабатываниями таймера называют квантовой единицей

Количество квантовых единиц между сменами активных потоков на одном ядре называется Значение Перезапуска Кванта (фактически это в народе и называют квантом

Это значение отличается как в зависимости от операционной системы так и от её версии: серверной или пользовательской. На клиентских системах Windows оно равно 6. Это значит, что количество квантовых единиц, выделяемых потоку для непрерывной работы, равно 6. Поэтому если на клиентской версии Windows пройдёт два такта системного таймера (на однопроцесорной Windows 10мс + 10мс = 20мс), то если учесть, что в такте 3 квантовой единицы, мы и получим значене перезапуска кванта = 6. Т.е. потоки на клиентской Windows меняются каждые 20 мс на однопроцессорной клиентской версии и каждые 30 мс на клиентской многопроцессорной версии.

Предположим, что один из потоков на уровне второй квантовой единицы встал в блокировку (рис. 6). Тогда чтобы процессор не простаивал, этот поток теряет квантовое время и оно отдаётся другому потоку. Другой поток начал свою работу

работу. Но поскольку планировщик запускается только когда срабатывает системный таймер, то следующий поток отработает дольше. Следующий же за ним поток отработает уже положенное время. Получается так, что если вы работаете с блокировками, то ваше приложение будет выполняться малое количество времени

Во время работы потока могут возникнуть аппаратные прерывания (INT). Прерывания это отвлечение процессора от выполнения текущего потока для выполнения более важных задач (получение состояния внешних устройств и т.п.). Обработка прерывания занимает время потока, но вас это не должно беспокоить потому, что время затраченное на обработку прерывания не учитывается в планировании и соответственно ваш поток отработает дольше. Далее, когда поток, освобождённый от блокировки, просыпается, то он дорабатывает своё значение квантового перезапуска.

Квантовая цель такты за 6 квантовых единиц

2) потоки и тред пул

Однако, создание потока -- это очень дорогая операция. Ведь что такое "создать поток"? Для начала это обращение в операционную систему. Обращение в операционную систему -- это преодоление барьера между слоем прикладного ПО и слоем операционной системы. Слои эти обеспечиваются процессором, а стороны барьеров - кольцами защиты. Прикладное программное обеспечение имеет кольцо защиты Ring 3, тогда как уровень ОС занимает кольцо Ring 0. Вызов методов из кольца в кольцо -- операция дорогая, а перехода между тем два: из Ring 3 в Ring 0 и обратно. Плюс создание стеков потока: один для Ring 3, второй -- для Ring 0. Плюс создание дополнительных структур данных со стороны .NET. В общем чтобы что-то исполнить параллельно чему-то быстро, для начала придётся потратить много времени

Однако люди заметили, что долгих операций, которые бы исполнялись непрерывно, не уходя в ожидание оборудования, мало. Скорее это выглядит так:
 1 Ожидание сети по вопросу подключения клиента
 2 Проанализировали запрос, сформировали запрос к БД, отправили
 3 Ожидание ответа от сервера БД
 4 Ответ получен, перевели в ответ от сервиса
 5 Отправили ответ
И пункты (2) и (4) -- не так долго выполняются. Скорее это -- очень короткие по времени исполнения участки кода. А потому стоит задаться вопросом: для чего под них создавать отдельные потоки (тут отсылка к неверному многими трактовании слова асинхронно и повсеместной попытки что-то отработать параллельно)? В конце концов цепочка (1) - (5) работает целиком последовательно, а это значит, что в точках (1), (3) и (5) поток исполнения находится в блокировке ожидания оборудования, т.к. ждёт ответа от сетевой карты. Т.е. не участвует в планировании операционной системой и никак не влияет на её производительность. Тогда что, web-серверу надо создать поток под всю цепочку? А если сервер обрабатывает 1000 подключений в секунду? Мы же помним, что один поток создаётся крайне долго. Значит он не сможет работать с такими скоростями если будет создавать под каждый запрос поток. Работать на уже существующих? Брать потоки в аренду?

Именно поэтому и возник пул потоков, ThreadPool. Он решает несколько задач:
 • с одной стороны он абстрагирует создание потока: мы этим заниматься не должны
 • создав когда-то поток, он исполняет на нём совершенно разные задачи. Вам же не важно, на каком из них исполняться? Главное чтобы был
 ◦ а потому мы более не тратим время на создание потока ОС: мы работаем на уже созданных
 ◦ а потому нагружая ThreadPool своими делегатами мы можем равномерно загрузить ядра CPU работой
 • либо ограничивает пропускную способность либо наоборот: даёт возможность работать на все 100% от всех процессорных ядер.

И если взглянуть на вопрос с той стороны что пул потоков -- это инструмент, то как следствие возникает вопрос: какие задачи должен решать этот инструмент?

Ведь в конечном счёте параллельно исполняющийся код -- просто набор множества задач, которым совершенно не важен поток, на котором они работают. Им важно исполняться параллельно друг другу. Вам даже не так важно количество. Вам важно, чтобы CPU расходовался оптимально.

Например, может показаться, что пул потоков создан чтобы решить разделение IO-/CPU-bound операции. И частично это так. Я бы сказал, что пул потоков предоставляет возможность разделения IO-/CPU-bound операций второго уровня. В том смысле, что разделение существует и без него и оно находится на более глубоком уровне, на уровне операционной системы

Блокировка -- это механизм ожидания сигнала от операционной системы что что-то произошло

Далее, если речь идёт о блокировке, срабатывает ряд достаточно простых механизмов, которые сначала проверяют состояние блокировки: установлена ли блокировка или нет, и если есть, поток переносится из очереди готовности к исполнению в список ожидания снятия блокировки. Что это значит? Поскольку операционная система руководствуется списком готовых к исполнению потоков при выборе того потока, который будет исполняться на процессоре, заблокированный поток она не заметит и потому не станет тратить на него ресурсы. Его просто нет в планировании. А потому легко сделать вывод, что когда поток встаёт в блокировку, он исчезает из планирования на исполнение и потому если все потоки находятся в блокировке, уровень загруженности процессора будет равен 0%.

Однако в случае большинства оборудования (например, сетевая карта, жёсткий диск и прочие) у вас будет одна задержка на синхронную подачу команды на оборудование (без перехода в блокировку, но с переходом в kernel space) и вторая задержка -- на ожидание ответа от оборудования. Большинство таких операций сопровождается постановкой потока в заблокированное состояние

Причиной этому служит разность в скорости работы процессора и оборудования, с которым производится взаимодействие: пока некоторая условная сетевая карта осуществляет посылку пакета и далее -- ожидает получения пакетов с ответом на процессорном ядре можно совершить миллионы, миллиарды операций

А потому пока идёт ответ от оборудования можно сделать много чего ещё и чтобы этого добиться поток переводится в заблокированное состояние и исключается из планирования, предоставив другим потокам возможность использовать для своей работы процессор.

Но возникает проблема: ожидание от оборудования происходит в потоке, который инициировал это ожидание. Т.е. если мы будем ожидать в пуле потоков, мы снизим его уровень параллелизма. Как это решить? Инженеры из Microsoft создали для этих целей внутри ThreadPool второй пул: пул ожидающих потоков. И когда некий код, работающий в основном пуле решается встать в блокировку, сделать он это должен не тут же, в основном пуле, а специальным образом: перепланировавшись на второй пул (об этом позже).

Работа запланированных к исполнению делегатов (давайте называть вещи своими именами) на нескольких рабочих потоках, а ожидание - на других, предназначенных для "спячки" реализует второй уровень разделения IO-/CPU-bound операций, когда уже приложение, а не операционная система получает механизм максимального занятия работой процессорных ядер

Однако помимо кода, который исполняет процессор (т.н. IO-bound код) существует также код, приводящий к блокировке исполнения потока: ожиданию ответа от оборудования. Клавиатура, мышь, сеть, диск и прочие сигналы от оборудования. Этот код называется IO-bound